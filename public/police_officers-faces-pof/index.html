<!DOCTYPE html>
<html lang="en" dir="ltr">
<head><script src="/asrg/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=asrg/livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="A large-scale facial recognition dataset encompassing approximately 90,000 images of thousands of law enforcement officers. This dataset has been meticulously curated to serve as a tool, equipping investigative journalists, human rights researchers, and digital activists with the necessary means to advance justice, foster transparency, and strengthen advocacy efforts. By facilitating critical inquiry and enabling informed action, the dataset aims to contribute to the ongoing efforts to hold systems of power accountable and promote the protection of fundamental rights.">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/asrg/police_officers-faces-pof/">
  <meta property="og:site_name" content="ASRG">
  <meta property="og:title" content="Police Officers Faces">
  <meta property="og:description" content="A large-scale facial recognition dataset encompassing approximately 90,000 images of thousands of law enforcement officers. This dataset has been meticulously curated to serve as a tool, equipping investigative journalists, human rights researchers, and digital activists with the necessary means to advance justice, foster transparency, and strengthen advocacy efforts. By facilitating critical inquiry and enabling informed action, the dataset aims to contribute to the ongoing efforts to hold systems of power accountable and promote the protection of fundamental rights.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
    <meta property="article:published_time" content="2024-06-17T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-11T00:00:00+00:00">
    <meta property="article:tag" content="Counter Surveillance">
    <meta property="article:tag" content="Scrapism">
    <meta property="article:tag" content="Copwatch">
    <meta property="article:tag" content="Social Engineering">
    <meta property="article:tag" content="OSINT">
    <meta property="article:tag" content="Artivism">
    <meta property="og:image" content="http://localhost:1313/asrg/images/output-787.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/asrg/images/output-787.png">
  <meta name="twitter:title" content="Police Officers Faces">
  <meta name="twitter:description" content="A large-scale facial recognition dataset encompassing approximately 90,000 images of thousands of law enforcement officers. This dataset has been meticulously curated to serve as a tool, equipping investigative journalists, human rights researchers, and digital activists with the necessary means to advance justice, foster transparency, and strengthen advocacy efforts. By facilitating critical inquiry and enabling informed action, the dataset aims to contribute to the ongoing efforts to hold systems of power accountable and promote the protection of fundamental rights.">


<title>
	Police Officers Faces - ASRG
</title>
<link rel="manifest" href="/asrg/manifest.json">
<link rel="icon" href="/asrg/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/asrg/book.min.db94fdc8cafe326bd4d36218d798d33e18985c8e1c0225c1f3ba77043588f348.css" integrity="sha256-25T9yMr&#43;MmvU02IY15jTPhiYXI4cAiXB87p3BDWI80g=" crossorigin="anonymous">
  <script defer src="/asrg/flexsearch.min.js"></script>
  <script defer src="/asrg/en.search.min.efbceee9ae028a0f6554d0934ca441d87748029f3e99e40a609634c7218c1c9b.js" integrity="sha256-77zu6a4Cig9lVNCTTKRB2HdIAp8&#43;meQKYJY0xyGMHJs=" crossorigin="anonymous"></script>

  <script defer src="/asrg/sw.min.bc8f0afcfd53af9e88bc7d3e1fdf33fc12a26b7abc7687de0097ba4ec6ee2bc0.js" integrity="sha256-vI8K/P1Tr56IvH0&#43;H98z/BKia3q8dofeAJe6TsbuK8A=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/asrg/">
    <img src="/asrg/logo_final_blue.svg" alt="ASRG" />
  </a>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Workshops</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/asrg/illegal-directions/" class="">Illegal Directions</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Interventions</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/asrg/technopolitics-of-fronts/" class="">Technopolitics of Fronts</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/asrg/police_officers-faces-pof/" class="active">Police Officers Faces</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Research</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/asrg/intertwined-feedback-loops/" class="">Intertwined Feedback Loops</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/asrg/manifesto-on-algorithmic_sabotage/" class="">Manifesto on “Algorithmic Sabotage”</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/asrg/theorizing-algorithmic_sabotage/" class="">Theorizing “Algorithmic Sabotage”</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>----</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/asrg/about/" class="">About </a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>











  
<ul>
  
  <li>
    <a href="/asrg/posts/" >
        Blog
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/asrg/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Police Officers Faces</strong>

  <label for="toc-control">
    
  </label>
</div>


  
 
      </header>

      
      
  <article class="markdown book-article">
<h1>Police Officers Faces (POF)</h1>

<ul class="subtitle">
	<li>A large-scale facial recognition dataset encompassing approximately 90,000 images of thousands of law enforcement officers. This dataset has been meticulously curated to serve as a tool, equipping investigative journalists, human rights researchers, and digital activists with the necessary means to advance justice, foster transparency, and strengthen advocacy efforts. By facilitating critical inquiry and enabling informed action, the dataset aims to contribute to the ongoing efforts to hold systems of power accountable and promote the protection of fundamental rights.</li>
	<li>
	Posted: Jun 17, 2024. Modified: Jan 11, 2025
	
</ul>
<div class="book-columns flex flex-wrap">
  <div class="flex-even markdown-inner">
    <div class="caption"><img src="images/output-274.gif">The <code>GIF</code> above displays 100 randomly selected sample images from the <em>“POF”</em> face recognition dataset, each annotated with the <code>Big Lips</code> facial attribute label. <span style="color:grey">In compliance with privacy considerations, all facial features have been redacted.</span></div>
  </div>
  <div class="flex-even markdown-inner">
    <div class="caption"><img src="images/output-367.gif">The <code>GIF</code> above displays 100 randomly selected sample images from the <em>“POF”</em> face recognition dataset, each annotated with the <code>Mouth Closed</code> facial attribute label. <span style="color:grey">In compliance with privacy considerations, all facial features have been redacted.</span></div>
  </div>
  <div class="flex-even markdown-inner">
    <div class="caption"><img src="images/output-536.gif">The <code>GIF</code> above displays 100 randomly selected sample images from the <em>“POF”</em> face recognition dataset, each annotated with the <code>Square Face</code> facial attribute label. <span style="color:grey">In compliance with privacy considerations, all facial features have been redacted.</span></div>
  </div>
</div>
<div class="book-columns flex flex-wrap">
  <div class="flex-even markdown-inner">
    <div class="caption"><img src="images/output-719.gif">The <code>GIF</code> above displays 100 randomly selected sample images from the <em>“POF”</em> face recognition dataset, each annotated with the <code>No Eyewear</code> facial attribute label. <span style="color:grey">In compliance with privacy considerations, all facial features have been redacted.</span></div>
  </div>
  <div class="flex-even markdown-inner">
    <div class="caption"><img src="images/output-827.gif">The <code>GIF</code> above displays 100 randomly selected sample images from the <em>“POF”</em> face recognition dataset, each annotated with the <code>Arched Eyebrows</code> facial attribute label. <span style="color:grey">In compliance with privacy considerations, all facial features have been redacted.</span></div>
  </div>
  <div class="flex-even markdown-inner">
    <div class="caption"><img src="images/output-897.gif">The <code>GIF</code> above displays 100 randomly selected sample images from the <em>“POF”</em> face recognition dataset, each annotated with the <code>Middle Aged</code> facial attribute label. <span style="color:grey">In compliance with privacy considerations, all facial features have been redacted.</span></div>
  </div>
</div>
<h2 id="context">
  Context
  <a class="anchor" href="#context">#</a>
</h2>
<p><em>“We live in the age of digital data, and in that age mathematics has become the parliament of politics. The social law has become interwoven with models, theorems and algorithms. With digital data, mathematics has become the dominant means in which human beings coordinate with technology … Mathematics is a human activity after all. Like any other human activity, it carries the possibilities of both emancipation and oppression.” — Politically Mathematics Manifesto, 2019<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></em></p>
<p>Across Europe and globally, artificial intelligence (AI) systems are increasingly developed and deployed in ways that facilitate harmful and discriminatory state surveillance practices. These systems often leverage biometric technologies for identification, recognition, and categorization, alongside predictive algorithms for decision-making and resource allocation. In law enforcement, these applications disproportionately target marginalized communities, erode legal and procedural protections, and facilitate mass surveillance. The deployment of AI in law enforcement, security, and migration control—including the policing of social security—exacerbates power asymmetries between authorities and those under surveillance. This heightened imbalance significantly increases the risk of harm, undermines fundamental rights, and poses serious threats to the rule of law.</p>
<p>Artificial intelligence (AI) not only undermines due process but also fosters a form of thoughtlessness, as political philosopher Hannah Arendt described when analyzing the actions of Nazi war criminal Adolf Eichmann. This thoughtlessness reflects an inability to critically evaluate instructions, a failure to reflect on the potential consequences, and an adherence to the belief that a correct and just process is being followed. In the context of AI&rsquo;s real-world impact, the primary concerns are discrimination and segregation. AI can be seen as a technology that perpetuates racism, reinforcing systems of racial and social segregation. In this sense, racism itself may be conceptualized as a technology of segregation, with AI playing a central role in its contemporary manifestation.</p>
<p>This is particularly evident in the deployment of facial recognition technology, which stands as one of the most contentious and ethically problematic applications of artificial intelligence (AI) to date. The concern extends beyond the mere fact that facial recognition systems exhibit lower accuracy rates when applied to individuals of color; more fundamentally, it lies in the way these technologies facilitate what Simone Browne terms <em>&lsquo;digital epidermalization&rsquo;—&rsquo;the exercise of power cast by the disembodied gaze of certain surveillance technologies… that can be employed to do the work of alienating the subject by producing a truth about the racial body and one’s identity (or identities) despite the subject’s claims.&rsquo;</em><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> In this context, facial recognition technology is implicated not only in reinforcing racialized power structures but also in the construction of a racialized truth that undermines individual autonomy and agency.</p>
<p>Facial recognition technology is a profoundly invasive, discriminatory, and biased mechanism. It reinforces structural power imbalances, perpetuates racial discrimination, sustains systems of racism, and facilitates authoritarian control. Within the European Union, AI-driven facial recognition systems are deployed in public spaces to capture and analyze facial features, classifying individuals into racial and ethnic categories such as Roma and Sinti. This process implicitly associates non-white individuals with suspicion, reinforcing racialized surveillance practices that exacerbate social inequalities and deepen the marginalization of racial and ethnic minorities.</p>
<p>The <em>Police Officers Faces (POF)</em> dataset is an investigative counter-surveillance artistic project that critically interrogates the deployment of facial recognition technology, with particular focus on its use by law enforcement agencies. The dataset comprises 88,783 facial images of thousands of police officers, meticulously collected from publicly accessible online sources and repurposed for facial recognition. By repurposing this data; the project challenges the ethical ramifications of surveillance technologies and critiques their capacity to normalize state power. In a bold inversion of the traditional surveillance paradigm—where the powerful observe and monitor the powerless—the <em>‘POF’</em> dataset shifts the surveillance gaze, enabling citizens to directly scrutinize those in positions of authority. This inversion disrupts the inherently one-sided nature of surveillance, stimulating critical reflection on the power dynamics underpinning these technologies, and raising essential questions about accountability, transparency, and the ethical use of surveillance in democratic societies.</p>
<p>To counter the dehumanizing effects of automated discrimination, systemic segregation, and the amplification of harm inherent in mass surveillance, the project proposes a radical alternative technical framework—a collective <em>‘counter-intelligence.’</em> This approach challenges the centralized control of surveillance technologies and emphasizes the transformative potential of citizens and grassroots movements in resisting and dismantling unjust systems. By employing a multifaceted methodology that integrates targeted data collection, social engineering, and rigorous analytical techniques, the <em>‘POF’</em> dataset offers a comprehensive structural alternative to prevailing surveillance models that disproportionately target marginalized communities. It not only empowers individuals engaged in copwatch, counter-surveillance, and other forms of resistance, but also equips them with the tools necessary to challenge and resist authoritarian oversight mechanisms. Furthermore, the project provides a platform for collective action, enabling grassroots movements to advocate for transparency, accountability, and justice within law enforcement practices.</p>
<h3 id="dataset-description">
  Dataset Description
  <a class="anchor" href="#dataset-description">#</a>
</h3>
<p>The <em>Police Officers Faces (POF)</em> dataset constitutes a meticulously curated collection of facial images of law enforcement officers, derived from publicly accessible online sources. The dataset comprises 88,783 aligned and cropped facial images, each formatted to a resolution of 200×280 pixels. Each image is centered on a single face, with the majority being labeled with the name of the individual depicted. On average, each individual is represented by <code>12.22</code> facial images. Unlike most existing facial recognition datasets, the images in this collection were obtained in entirely uncontrolled settings, with subjects who were uncooperative. Consequently, the dataset exhibits considerable variability across multiple dimensions, including pose, resolution, lighting conditions, facial expressions, scene composition, imaging conditions, and other technical parameters.</p>
<p>The dataset includes JPEG-formatted images supplemented by detailed metadata stored in <code>JSON</code> and <code>CSV</code> formats. Part of this metadata encompasses facial bounding box coordinates and biometric landmark data, providing a robust framework for advanced analysis. Furthermore, the dataset includes comprehensive personal identifiers, such as the full names of the depicted individuals, enhancing its utility for identification, verification, and recognition tasks. In addition, each facial image is annotated with seventy-three distinct attributes, organized into three primary recognition domains: age group, gender, and a diverse array of visual characteristics. These visual traits encompass attributes such as hair color, face shape, and the presence of makeup, thereby enabling multifaceted recognition and analytical capabilities.</p>
<p><span style="color:grey">* Please be advised that the information presented on this page serves as an initial overview. It is subject to updates and revisions as new data and insights become available, ensuring the accuracy and comprehensiveness of the content.</span></p>
<h2 id="license-agreement">
  License Agreement
  <a class="anchor" href="#license-agreement">#</a>
</h2>
<p>Any entity utilizing the <em>Police Officers Faces (POF)</em> dataset acknowledges and agrees to adhere to the following terms and conditions:</p>
<blockquote class="book-hint danger">
  <ul>
<li>
<p><strong>Non-Commercial Use:</strong> The dataset, along with its subsets, is made available exclusively for non-commercial research purposes. The reproduction, duplication, copying, sale, trade, resale, or any form of exploitation—whether direct or indirect—of the dataset or any derived data for commercial purposes is strictly prohibited.</p>
</li>
<li>
<p><strong>No Warranty:</strong> The dataset is made available without any express or implied warranties. The user assumes full responsibility for their use of the dataset and acknowledges the inherent risks associated with the exercise of the rights granted under this license. The administrator of the <em>Police Officers Faces (POF)</em> dataset explicitly disclaims any liability for damages—whether physical, financial, or otherwise—arising from the use of the dataset.</p>
</li>
<li>
<p><strong>No Distribution:</strong> Redistribution or sublicensing of the dataset, in whole or in part, to any third party is prohibited. This prohibition extends to any form of publication, copying, dissemination, or distribution to any organization, entity, or individual.</p>
</li>
<li>
<p><strong>No Modification:</strong> Users are expressly prohibited from modifying, altering, or adapting the dataset in any form or manner.</p>
</li>
</ul>
</blockquote>
<h2 id="supplemental-information">
  Supplemental Information
  <a class="anchor" href="#supplemental-information">#</a>
</h2>
<h3 id="annotated-sample-images">
  Annotated Sample Images
  <a class="anchor" href="#annotated-sample-images">#</a>
</h3>
<p>The following section presents a randomly selected subset of sample images, each annotated with the corresponding seventy-three attribute labels. The frequency distribution of these labels has been visualized using the <a href="https://matplotlib.org/" target="_blank">Matplotlib</a> library. To preserve the privacy of the individuals depicted, the faces in the images have been redacted.</p>
<div class="caption"><img src="plots/plt-g8ltccwb.png"
       alt=" ">The plot above illustrates the frequency distribution of the attribute labels corresponding to the image identified by <code>"image_id": "g8ltccwb"</code>. <a href="data/g8ltccwb.csv">Download data as CSV</a></div>
<tr><td>&nbsp;</td></tr>
<div class="caption"><img src="plots/plt-8g5e6p7g.png"
       alt=" ">The plot above illustrates the frequency distribution of the attribute labels corresponding to the image identified by <code>"image_id": "8g5e6p7g"</code>. <a href="data/8g5e6p7g.csv">Download data as CSV</a></div>
<tr><td>&nbsp;</td></tr>
<div class="caption"><img src="plots/plt-lo7zii72.png"
       alt=" ">The plot above illustrates the frequency distribution of the attribute labels corresponding to the image identified by <code>"image_id": "lo7zii72"</code>. <a href="data/lo7zii72.csv">Download data as CSV</a></div>
<tr><td>&nbsp;</td></tr>
<div class="caption"><img src="plots/plt-vnqvu49b.png"
       alt=" ">The plot above illustrates the frequency distribution of the attribute labels corresponding to the image identified by <code>"image_id": "vnqvu49b"</code>. <a href="data/vnqvu49b.csv">Download data as CSV</a></div>
<tr><td>&nbsp;</td></tr>
<div class="caption"><img src="plots/plt-ek1qpg59.png"
       alt=" ">The plot above illustrates the frequency distribution of the attribute labels corresponding to the image identified by <code>"image_id": "ek1qpg59"</code>. <a href="data/ek1qpg59.csv">Download data as CSV</a></div>
<p><span style="color:grey">* It is important to note that this specific section of the dataset employs a model with inherent limitations, which categorizes faces in a strictly discriminative manner. Additionally, the ground truth for the face attribute annotations is derived through automatic estimation, and these annotations have not been independently verified by human annotators.</span></p>
<h3 id="access">
  Access
  <a class="anchor" href="#access">#</a>
</h3>
<p>The <em>Police Officers Faces (POF)</em> dataset, version <code>0.1.0</code>, is currently not accessible to the general public. It is specifically designed to equip investigative journalists, human rights researchers, and digital activists with the means to strengthen justice and advocacy efforts.</p>
<h3 id="citations">
  Citations
  <a class="anchor" href="#citations">#</a>
</h3>
<ul>
<li>
<p><a href="https://icespy.org/" target="_blank">ICEspy</a> by <a href="https://kylemcdonald.net/" target="_blank">Kyle McDonald</a>, 2018: <em>“Concerned you may know an ICE employee? Use this helpful app to check. Just point your camera and press the photo button. We&rsquo;ll check against hundreds of ICE employee photos from LinkedIn and show you the closest match. A direct subversion of face recognition technology to watch those who wield power without responsibility.”</em></p>
</li>
<li>
<p><a href="https://paolocirio.net/work/capture/" target="_blank">Capture</a> by <a href="https://paolocirio.net/" target="_blank">Paolo Cirio</a>, 2020: <em>“The series of photos Capture is composed of French police officers’ faces. Paolo Cirio collected 1000 public images of police in photos taken during protests in France and processed them with Facial Recognition software. Cirio then created an online platform with a database of the resulting 4000 faces of police officers to crowdsource their identification by name.”</em></p>
</li>
<li>
<p><a href="https://coppelganger.lav.io/" target="_blank">NYPD COPPELGÄNGER</a> by <a href="https://lav.io/" target="_blank">Sam Lavigne</a>, 2024: <em>“Facial recognition on an archive of ~10,000 photos of New York cops. Images are publicly available and sourced from <a href="https://www.50-a.org/" target="_blank">50-a.org</a> and then processed using <a href="https://github.com/serengil/deepface" target="_blank">Deepface</a> with the yunet model for facial detection and Facenet512 for recognition.”</em></p>
</li>
</ul>
<h3 id="credits">
  Credits
  <a class="anchor" href="#credits">#</a>
</h3>
<h4 id="software">
  Software
  <a class="anchor" href="#software">#</a>
</h4>
<p>The majority of this project was developed utilizing open-source software tools. Core software application development and data analysis were conducted using <a href="https://www.python.org/" target="_blank">Python</a>, alongside key software libraries and tools such as <a href="https://pandas.pydata.org/" target="_blank">Pandas</a>, <a href="https://en.wikipedia.org/wiki/Markdown" target="_blank">Markdown</a>, and <a href="https://matplotlib.org/" target="_blank">Matplotlib</a>, as well as other widely recognized open-source packages. All of these resources were freely available to support the project&rsquo;s objectives. Communication throughout the project was facilitated using <a href="https://signal.org/" target="_blank">Signal</a>, an open-source service for encrypted instant messaging, voice, and video calls, while face redaction was performed using the open-source <a href="https://github.com/vframeio/dface" target="_blank">DFACE.app</a> web application.</p>
<h4 id="image">
  Image
  <a class="anchor" href="#image">#</a>
</h4>
<p>Front Page Image: A mosaic comprising approximately 63,000 facial images of law enforcement officers from the <em>Police Officers Faces (POF)</em> facial recognition dataset. The images have been strategically downsized to protect the privacy and confidentiality of the individuals depicted, ensuring compliance with ethical standards and privacy considerations. <span style="color:grey">Mosaic: © Algorithmic Sabotage Research Group (ASRG).</span></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Politically Mathematics collective, “Politically Mathematics Manifesto,” 2019. <a href="https://politicallymath.in/manifesto/" target="_blank">https://politicallymath.in/manifesto/</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Browne, S. 2015. Dark Matters: On the Surveillance of Blackness. Durham, NC: Duke University Press Books.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        <div class="footer">
	<p>Unless otherwise noted all text, images, and media &copy; Algorithmic Sabotage Research Group</p>
</div>

      </footer>

      
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
  </main>

  
</body>
</html>












